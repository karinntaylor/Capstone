{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model #2: Decision tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikeShare = pd.read_csv('bikeshare2020model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = DecisionTreeRegressor(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting out dataset by start station names to create models for each start station\n",
    "dtdf1 = bikeShare.loc[bikeShare['Start Station Name'] == 'Queens Quay E / Lower Sherbourne St']\n",
    "dtdf2 = bikeShare.loc[bikeShare['Start Station Name'] == 'Lake Shore Blvd W / Ontario Dr']\n",
    "dtdf3 = bikeShare.loc[bikeShare['Start Station Name'] == 'Marilyn Bell Park Tennis Court']\n",
    "dtdf4 = bikeShare.loc[bikeShare['Start Station Name'] == 'HTO Park (Queens Quay W)']\n",
    "dtdf5 = bikeShare.loc[bikeShare['Start Station Name'] == 'York St / Queens Quay W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set X and Y\n",
    "dtX1 = dtdf1[['Time Labels', 'Day of Week', 'Month', 'Day', 'Mean Temp (°C)', 'Total Precip (mm)']]\n",
    "dtX2 = dtdf2[['Time Labels', 'Day of Week', 'Month', 'Day', 'Mean Temp (°C)', 'Total Precip (mm)']]\n",
    "dtX3 = dtdf3[['Time Labels', 'Day of Week', 'Month', 'Day', 'Mean Temp (°C)', 'Total Precip (mm)']]\n",
    "dtX4 = dtdf4[['Time Labels', 'Day of Week', 'Month', 'Day', 'Mean Temp (°C)', 'Total Precip (mm)']]\n",
    "dtX5 = dtdf5[['Time Labels', 'Day of Week', 'Month', 'Day', 'Mean Temp (°C)', 'Total Precip (mm)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dty1 = dtdf1['Ride Count']\n",
    "dty2 = dtdf2['Ride Count']\n",
    "dty3 = dtdf3['Ride Count']\n",
    "dty4 = dtdf4['Ride Count']\n",
    "dty5 = dtdf5['Ride Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training and testing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features1, testing_features1, training_labels1, testing_labels1 = train_test_split(dtX1, dty1, test_size = 0.25, random_state = 42)\n",
    "training_features2, testing_features2, training_labels2, testing_labels2 = train_test_split(dtX2, dty2, test_size = 0.25, random_state = 42)\n",
    "training_features3, testing_features3, training_labels3, testing_labels3 = train_test_split(dtX3, dty3, test_size = 0.25, random_state = 42)\n",
    "training_features4, testing_features4, training_labels4, testing_labels4 = train_test_split(dtX4, dty4, test_size = 0.25, random_state = 42)\n",
    "training_features5, testing_features5, training_labels5, testing_labels5 = train_test_split(dtX5, dty5, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train models\n",
    "dtreg1 = regressor.fit(training_features1, training_labels1)\n",
    "dtreg2 = regressor.fit(training_features2, training_labels2)\n",
    "dtreg3 = regressor.fit(training_features3, training_labels3)\n",
    "dtreg4 = regressor.fit(training_features4, training_labels4)\n",
    "dtreg5 = regressor.fit(training_features5, training_labels5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(regressor, out_file ='tree1.dot',\n",
    "               feature_names =['Time Labels', 'Day of Week', 'Month', 'Day', 'Mean Temp (°C)', 'Total Precip (mm)']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the models to make predictions\n",
    "y_pred1 = dtreg1.predict(testing_features1)\n",
    "y_pred2 = dtreg2.predict(testing_features2)\n",
    "y_pred3 = dtreg3.predict(testing_features3)\n",
    "y_pred4 = dtreg4.predict(testing_features4)\n",
    "y_pred5 = dtreg5.predict(testing_features5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the models\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 22.661242025777895\n",
      "Mean Squared Error: 1167.3213123291239\n",
      "Root Mean Squared Error: 34.166084240502656\n",
      "r2:  0.6459\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(testing_labels1, y_pred1))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(testing_labels1, y_pred1))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(testing_labels1, y_pred1)))\n",
    "print('r2: ', round(metrics.r2_score(testing_labels1, y_pred1),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 46.063209290050146\n",
      "Mean Squared Error: 4191.033913961467\n",
      "Root Mean Squared Error: 64.73819517071408\n",
      "r2:  0.3111\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(testing_labels2, y_pred2))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(testing_labels2, y_pred2))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(testing_labels2, y_pred2)))\n",
    "print('r2: ', round(metrics.r2_score(testing_labels2, y_pred2),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 29.628445925477127\n",
      "Mean Squared Error: 1955.1697970312027\n",
      "Root Mean Squared Error: 44.217302009860376\n",
      "r2:  0.5281\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(testing_labels3, y_pred3))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(testing_labels3, y_pred3))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(testing_labels3, y_pred3)))\n",
    "print('r2: ', round(metrics.r2_score(testing_labels3, y_pred3),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 19.00786430223593\n",
      "Mean Squared Error: 753.6228218966846\n",
      "Root Mean Squared Error: 27.452191568191502\n",
      "r2:  0.686\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(testing_labels4, y_pred4))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(testing_labels4, y_pred4))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(testing_labels4, y_pred4)))\n",
    "print('r2: ', round(metrics.r2_score(testing_labels4, y_pred4),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.028338813214341632\n",
      "Mean Squared Error: 0.2788476593079693\n",
      "Root Mean Squared Error: 0.5280602799945943\n",
      "r2:  0.9998\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(testing_labels5, y_pred5))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(testing_labels5, y_pred5))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(testing_labels5, y_pred5)))\n",
    "print('r2: ', round(metrics.r2_score(testing_labels5, y_pred5),4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
